{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이토치 기본\n",
    "- 기본 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 파이토치 \n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파이토치 패키지 구성\n",
    "- **torch**\n",
    "    - 메인 네임스페이스. 텐서(진짜 기본) 및 수학함수(sin,cos,tan...) 포함. numpy와 유사한 구조\n",
    "    - numpy와 쉽게 변환\n",
    "- **torch.autograd** \n",
    "    - 자동 미분을 위한 함수 포함. 컨텍스트 매니저, 기반 클래스 및 함수 포함 \n",
    "\n",
    "- **torch.nn / torch.nn.functional** \n",
    "    - nn(Neural network). 딥러닝 신경망을 구축시 필요한 데이터 구조, 레이어 정의가 포함. Rnn, LSTM 레이어 및 ReLU, MESLoss 등 Tensorflow에 있는 함수 및 모델 포함\n",
    "\n",
    "- **toach.optim**\n",
    "    - 확률적 경사 하강법(SGD, Stochastic Gradient Descent) 중심 파라미터 최적화 알고리즘 포함 \n",
    "\n",
    "- **torch.utils.data**\n",
    "    - SGD 반복 연산 시 Batch(컴퓨터 자동 백그라운드로 실행) 유틸리티가 포함\n",
    "\n",
    "- **torch.onnx**\n",
    "    - Open Neural Network eXchange 포맷의 모델 포함. onnx 확장자로 export하면 PyTorch를 Tensorflow나 다른 딥러닝, 머신러닝 라이브러리에서 사용 가능 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파이토치 기초\n",
    "\n",
    "##### 텐서(Tensor) \n",
    "- 파이토치에서 데이터를 저장하는 자료구조\n",
    "- 텐서플로도 기본 텐서, numpy와 성격과 사용법이 거의 흡사 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 배열, 크기 3 으로 numpy 작성 \n",
    "data = [1, 3, 5] \n",
    "np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 배열, 크기 3 으로 tensor 작성 \n",
    "torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [[1,2,3,4], [5,6,7,8]]\n",
    "arr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차원 배열, 2행 4열 numpy \n",
    "np2_data = np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차원 배열, 2행 4열 tensor\n",
    "tc2_Data = torch.tensor(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tensor 하위구조 명칭\n",
    "<img src = \"https://camo.githubusercontent.com/814efc38b1d8ae9cf47a24e12c8aae325fb3ab56e04c601d98c967d2a182e758/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6875676f4d4753756e672f73747564792d7079746f7263682f6d61696e2f696d616765732f746f726368303030332e706e67\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1차원 tensor : Vector 벡터\n",
    "- 2차원 tensor : Matrix 매트릭스 \n",
    "- 3차원 이상 tensor : Tensor 텐서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이와 토치의 배열 크기 \n",
    "print(np2_data.shape, tc2_Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이의 정수 기본 타입 : int32 / 파이토치의 정수 기본 타입 : int64 \n",
    "print(np2_data.dtype, tc2_Data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서를 만들때 타입을 지정해서 변경가능 \n",
    "torch.tensor(data=arr, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 텐서의 데이터 \n",
    "- 실수계산 시 FloatTensor, 정수 LongTensor, True/Flase는 ByteTensor \n",
    "\n",
    "- ByteTensor, CharTensor - int 8\n",
    "- ShortTensor - int 16\n",
    "- IntTensor - int 32\n",
    "- LongTensor - int 64\n",
    "- HalfTensor - float16\n",
    "- FloatTensor  float32\n",
    "- DoubleTensor - Float64 \n",
    "\n",
    "- 참조 : https://subinium.github.io/pytorch-Tensor-Variable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터타입으로 변환시 \n",
    "tc2_Data.type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 텐서 구조 상태 확인\n",
    "- tensor.shape, tensor,.size() # 텐서의 크기\n",
    "- tensor.dtype, tensor,.type()\n",
    "    - dtype 타입, type() # 객체의 클래스 타입 \n",
    "- tensor.ndim, tensor.dim() #텐서의 차원\n",
    "- tensor.numel() # 전체 원소 갯수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 \n",
    "tns1_data = torch.tensor([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매트릭스 \n",
    "tns2_data = torch.tensor([[1,2,3,4],[5,6,7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이로 3차원 생성, 텐서 \n",
    "tns3_data = torch.tensor(np.arrage(27).reshape(3,3,3))\n",
    "tns3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 원소 갯수 \n",
    "print(f'Vector num = {tns1_data.numel()} \\nMatrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 넘파이와 파이토치 텐서간 변환 쉬움\n",
    "- 넘파이 함수와 동일한 함수 존재 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## zeros\n",
    "torch.zeros(2,4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이썬과 같이 인덱싱, 슬라이싱 가능 \n",
    "tns2_data[0][1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  4,  6],\n",
       "        [ 8, 10, 12]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬합 \n",
    "x1 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "torch.add(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  9],\n",
       "        [16, 25, 36]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬곱 \n",
    "x1 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "torch.mul(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22, 28],\n",
       "        [49, 64]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 매트릭스 연산 : 첫번째 매트릭스 열 크기와 두번째 매트리스 행크기가 일치 \n",
    "x3 = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "torch.mm(x1, x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU 메모리에서 GPU메모리로 데이터 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 현재의 데이터가 어느 메모리에 있는지 \n",
    "x3.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cpu 디바이스 = 'cpu'\n",
    "cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU 디바이스 = 'cuda'\n",
    "gpu = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x4 \u001b[38;5;241m=\u001b[39m \u001b[43mx3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m x4\n",
      "File \u001b[1;32mc:\\DEV\\Langs\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m     )\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "x4 = x3.to(gpu)\n",
    "x4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
